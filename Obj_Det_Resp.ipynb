{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Obj Det Resp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb37zJgyUy7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nCOGFxKsz79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add path environment\n",
        "PERSONAL_DIR = \"/content/drive/My Drive/\"\n",
        "BASE_DIR = PERSONAL_DIR + \"models/\"\n",
        "%set_env PYTHONPATH=/content/drive/My Drive/Laeveteinn/KopiOey/models/research:/content/drive/My Drive/Laeveteinn/KopiOey/models/research/slim\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/drive/My Drive/models\"\n",
        "import sys\n",
        "sys.path.insert(1, os.path.join(BASE_DIR, \"official\"))\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ZlblEdU3bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U --pre tensorflow==\"2.*\"\n",
        "!pip install tf_slim\n",
        "!pip install pycocotools\n",
        "!pip install keyboard\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BujGJ6ynVHjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLONE DE GIT\n",
        "# try:\n",
        "#   if \"drive/My\\ Drive/models\" in pathlib.Path.cwd().parts:\n",
        "#     while \"drive/My\\ Drive/models\" in pathlib.Path.cwd().parts:\n",
        "#       os.chdir('/content/drive/My Drive')\n",
        "#   elif not pathlib.Path('drive/My\\ Drive/models').exists():\n",
        "#     os.chdir('/content/drive/My Drive')\n",
        "#     !git clone --depth 1 https://github.com/tensorflow/models\n",
        "# except:\n",
        "#   None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0GZaooNVPZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile proto files\n",
        "# make sure you are in BASE_DIR/research/ (see cell below)\n",
        "%cd /content/drive/My Drive/models/research/\n",
        "# !protoc object_detection/protos/*.proto --python_out=.\n",
        "# !cp object_detection/packages/tf2/setup.py .\n",
        "# !python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-XifOKSVRUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.getcwd())\n",
        "os.chdir(\"/content/drive/My Drive/models/research/object_detection\")\n",
        "print(os.getcwd())\n",
        "try:\n",
        "  DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
        "  MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
        "  for dir in [DATA_DIR, MODELS_DIR]:\n",
        "    if not os.path.exists(dir):\n",
        "      os.mkdir(dir)\n",
        "except:\n",
        "  print('error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9tM2U5oVTGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# os.chdir('/research')\n",
        "\n",
        "# Download and extract model\n",
        "MODEL_DATE = '20200711'\n",
        "#'efficientdet_d2_coco17_tpu-32' #my primary model\n",
        "#'centernet_resnet101_v1_fpn_512x512_coco17_tpu-8' #secondary model (worst)\n",
        "#'efficientdet_d3_coco17_tpu-32' #third model (should be finest)\n",
        "MODEL_NAME = 'efficientdet_d3_coco17_tpu-32'\n",
        "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
        "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
        "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
        "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
        "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
        "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
        "if not os.path.exists(PATH_TO_CKPT):\n",
        "  print('Downloading model. This may take a while... ', end='')\n",
        "  urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
        "  tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
        "  tar_file.extractall(MODELS_DIR)\n",
        "  tar_file.close()\n",
        "  os.remove(PATH_TO_MODEL_TAR)\n",
        "  print('Done')\n",
        "\n",
        "# Download labels file\n",
        "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
        "LABELS_DOWNLOAD_BASE = \\\n",
        "    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
        "PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\n",
        "if not os.path.exists(PATH_TO_LABELS):\n",
        "  print('Downloading label file... ', end='')\n",
        "  urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n",
        "  print('Done')# %%bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBXeXmJjVWzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr5OHBZFVa-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(PATH_TO_CFG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS30S2jAVb6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/models/research')\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "os.chdir('/content/drive/My Drive/models')\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# for gpu in gpus:\n",
        "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SW3GzobVc_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhOwPuDVeVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(category_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss9LviHCVfhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3cvJL9jxOJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Python3 program to find if 2 given line segments intersect or not \n",
        "  \n",
        "class Point: \n",
        "    def __init__(self, x, y): \n",
        "        self.x = x \n",
        "        self.y = y \n",
        "  \n",
        "# Given three colinear points p, q, r, the function checks if  \n",
        "# point q lies on line segment 'pr'  \n",
        "def onSegment(p, q, r): \n",
        "    if ( (q.x <= max(p.x, r.x)) and (q.x >= min(p.x, r.x)) and \n",
        "           (q.y <= max(p.y, r.y)) and (q.y >= min(p.y, r.y))): \n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "def orientation(p, q, r): \n",
        "    # to find the orientation of an ordered triplet (p,q,r) \n",
        "    # function returns the following values: \n",
        "    # 0 : Colinear points \n",
        "    # 1 : Clockwise points \n",
        "    # 2 : Counterclockwise \n",
        "      \n",
        "    # See https://www.geeksforgeeks.org/orientation-3-ordered-points/amp/  \n",
        "    # for details of below formula.  \n",
        "      \n",
        "    val = (float(q.y - p.y) * (r.x - q.x)) - (float(q.x - p.x) * (r.y - q.y)) \n",
        "    if (val > 0): \n",
        "          \n",
        "        # Clockwise orientation \n",
        "        return 1\n",
        "    elif (val < 0): \n",
        "          \n",
        "        # Counterclockwise orientation \n",
        "        return 2\n",
        "    else: \n",
        "          \n",
        "        # Colinear orientation \n",
        "        return 0\n",
        "  \n",
        "# The main function that returns true if  \n",
        "# the line segment 'p1q1' and 'p2q2' intersect. \n",
        "def doIntersect(p1,q1,p2,q2): \n",
        "      \n",
        "    # Find the 4 orientations required for  \n",
        "    # the general and special cases \n",
        "    o1 = orientation(p1, q1, p2) \n",
        "    o2 = orientation(p1, q1, q2) \n",
        "    o3 = orientation(p2, q2, p1) \n",
        "    o4 = orientation(p2, q2, q1) \n",
        "  \n",
        "    # General case \n",
        "    if ((o1 != o2) and (o3 != o4)): \n",
        "        return True\n",
        "  \n",
        "    # Special Cases \n",
        "  \n",
        "    # p1 , q1 and p2 are colinear and p2 lies on segment p1q1 \n",
        "    if ((o1 == 0) and onSegment(p1, p2, q1)): \n",
        "        return True\n",
        "  \n",
        "    # p1 , q1 and q2 are colinear and q2 lies on segment p1q1 \n",
        "    if ((o2 == 0) and onSegment(p1, q2, q1)): \n",
        "        return True\n",
        "  \n",
        "    # p2 , q2 and p1 are colinear and p1 lies on segment p2q2 \n",
        "    if ((o3 == 0) and onSegment(p2, p1, q2)): \n",
        "        return True\n",
        "  \n",
        "    # p2 , q2 and q1 are colinear and q1 lies on segment p2q2 \n",
        "    if ((o4 == 0) and onSegment(p2, q1, q2)): \n",
        "        return True\n",
        "  \n",
        "    # If none of the cases \n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_K8b7xVXmta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_centroid(frame, centroid):\n",
        "  red = (0, 0, 255)\n",
        "  value = tuple(centroid)\n",
        "  cv2.circle(frame, value, 1, red, 10)\n",
        "\n",
        "def draw_text(frame, centroid, id):\n",
        "  centroid = tuple(centroid)\n",
        "  green = (0, 255, 0)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  cv2.putText(frame, \"Person #\" + str(id), centroid, font, 2, green, 2, cv2.LINE_AA)\n",
        "\n",
        "def draw_counter_text(frame, count):\n",
        "  position = (100,100)\n",
        "  green = (0, 0, 255)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  cv2.putText(frame, \"Counter :\" + str(count), position, font, 3, green, 3, cv2.LINE_AA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7qLV6khV9Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial import distance as dist\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "class CentroidTracker():\n",
        "\tdef __init__(self, frame_shape, maxDisappeared=50):\n",
        "\t\t# initialize the next unique object ID along with two ordered\n",
        "\t\t# dictionaries used to keep track of mapping a given object\n",
        "\t\t# ID to its centroid and number of consecutive frames it has\n",
        "\t\t# been marked as \"disappeared\", respectively\n",
        "\t\tself.counter = 0\n",
        "\t\tself.nextObjectID = 0\n",
        "\t\tself.objects = OrderedDict()\n",
        "\t\tself.disappeared = OrderedDict()\n",
        "\t\t# Height, width and color channel of the frame\n",
        "\t\tself.height, self.width, self.channel = frame_shape\n",
        "\n",
        "\t\t# store the number of maximum consecutive frames a given\n",
        "\t\t# object is allowed to be marked as \"disappeared\" until we\n",
        "\t\t# need to deregister the object from tracking\n",
        "\t\tself.maxDisappeared = maxDisappeared\n",
        "\n",
        "\tdef register(self, centroid):\n",
        "\t\t# when registering an object we use the next available object\n",
        "\t\t# ID to store the centroid\n",
        "\t\tself.objects[self.nextObjectID] = centroid\n",
        "\t\tself.disappeared[self.nextObjectID] = 0\n",
        "\t\tself.nextObjectID += 1\n",
        "\n",
        "\tdef deregister(self, objectID):\n",
        "\t\t# to deregister an object ID we delete the object ID from\n",
        "\t\t# both of our respective dictionaries\n",
        "\t\tdel self.objects[objectID]\n",
        "\t\tdel self.disappeared[objectID]\n",
        "\n",
        "\tdef update(self, frame, rects, ROI_start_point, ROI_end_point):\n",
        "\n",
        "\t\tdraw_counter_text(frame,self.counter)\n",
        "\t\n",
        "\t\t# check to see if the list of input bounding box rectangles\n",
        "\t\t# is empty\n",
        "\t\tif len(rects) == 0:\n",
        "\t\t\t# loop over any existing tracked objects and mark them\n",
        "\t\t\t# as disappeared\n",
        "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
        "\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t# if we have reached a maximum number of consecutive\n",
        "\t\t\t\t# frames where a given object has been marked as\n",
        "\t\t\t\t# missing, deregister it\n",
        "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\t# return early as there are no centroids or tracking info\n",
        "\t\t\t# to update\n",
        "\t\t\treturn self.objects\n",
        "\n",
        "\t\t# initialize an array of input centroids for the current frame\n",
        "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "\n",
        "\t\t# loop over the bounding box rectangles\n",
        "\t\tfor (i, (endY, endX, startY, startX)) in enumerate(rects):\n",
        "\t\t\t# denormalize the bounding box coordinate\n",
        "\t\t\td_minX = startX * self.height\n",
        "\t\t\td_maxX = endX * self.height\n",
        "\t\t\td_minY = startY * self.width\n",
        "\t\t\td_maxY = endY * self.width\n",
        "\t\t\t# use the bounding box coordinates to derive the centroid\n",
        "\t\t\tcX = int((d_minX + d_maxX) / 2.0)\n",
        "\t\t\tcY = int((d_minY + d_maxY) / 2.0)\n",
        "\t\t\tinputCentroids[i] = (cX, cY)\n",
        "\n",
        "\t\t# if we are currently not tracking any objects take the input\n",
        "\t\t# centroids and register each of them\n",
        "\t\tif len(self.objects) == 0:\n",
        "\t\t\tfor i in range(0, len(inputCentroids)):\n",
        "\t\t\t\tdraw_centroid(frame, inputCentroids[i])\n",
        "\t\t\t\tself.register(inputCentroids[i])\n",
        "\t\t\t\tdraw_text(frame, inputCentroids[i], self.nextObjectID-1)\n",
        "\n",
        "\t\t# otherwise, are are currently tracking objects so we need to\n",
        "\t\t# try to match the input centroids to existing object\n",
        "\t\t# centroids\n",
        "\t\telse:\n",
        "\t\t\t# grab the set of object IDs and corresponding centroids\n",
        "\t\t\tobjectIDs = list(self.objects.keys())\n",
        "\t\t\tobjectCentroids = list(self.objects.values())\n",
        "\n",
        "\t\t\t# compute the distance between each pair of object\n",
        "\t\t\t# centroids and input centroids, respectively -- our\n",
        "\t\t\t# goal will be to match an input centroid to an existing\n",
        "\t\t\t# object centroid\n",
        "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
        "\n",
        "\t\t\t# in order to perform this matching we must (1) find the\n",
        "\t\t\t# smallest value in each row and then (2) sort the row\n",
        "\t\t\t# indexes based on their minimum values so that the row\n",
        "\t\t\t# with the smallest value as at the *front* of the index\n",
        "\t\t\t# list\n",
        "\t\t\trows = D.min(axis=1).argsort()\n",
        "\n",
        "\t\t\t# next, we perform a similar process on the columns by\n",
        "\t\t\t# finding the smallest value in each column and then\n",
        "\t\t\t# sorting using the previously computed row index list\n",
        "\t\t\tcols = D.argmin(axis=1)[rows]\n",
        "\n",
        "\t\t\t# in order to determine if we need to update, register,\n",
        "\t\t\t# or deregister an object we need to keep track of which\n",
        "\t\t\t# of the rows and column indexes we have already examined\n",
        "\t\t\tusedRows = set()\n",
        "\t\t\tusedCols = set()\n",
        "\n",
        "\t\t\t# loop over the combination of the (row, column) index\n",
        "\t\t\t# tuples\n",
        "\t\t\tfor (row, col) in zip(rows, cols):\n",
        "\t\t\t\t# Keep drawing text for counter\n",
        "\t\t\t\t# draw_counter_text(frame,self.counter)\n",
        "\n",
        "\t\t\t\t# if we have already examined either the row or\n",
        "\t\t\t\t# column value before, ignore it\n",
        "\t\t\t\t# val\n",
        "\t\t\t\tif row in usedRows or col in usedCols:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
        "\t\t\t\tobjectID = objectIDs[row]\n",
        "\n",
        "\t\t\t\t# COUNTER DEBUG\n",
        "\t\t\t\t#print(\"old objects[objectID] :\",self.objects[objectID][0]) #<<<<<<<<<------------\n",
        "\t\t\t\t#print(\"new objects[objectID] :\",int(inputCentroids[col][0]), int(inputCentroids[col][1]))\n",
        "\n",
        "\t\t\t\t# counting thingy\n",
        "\t\t\t\tif (self.objects[objectID]).all():\n",
        "\t\t\t\t\tbeforeMove = Point(int(self.objects[objectID][0]), int(self.objects[objectID][1]))\n",
        "\t\t\t\t\tafterMove = Point(int(inputCentroids[col][0]), int(inputCentroids[col][1]))\n",
        "\t\t\t\t\n",
        "\t\t\t\t\tif doIntersect(ROI_start_point, ROI_end_point, beforeMove, afterMove):\n",
        "\t\t\t\t\t\tself.counter += 1\n",
        "\t\t\t\t#print(self.counter)\n",
        "\t\t\n",
        "\t\t\t\t# set its new centroid, and reset the disappeared\n",
        "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
        "\t\t\t\tself.disappeared[objectID] = 0\n",
        "\t\t\t\tdraw_centroid(frame, inputCentroids[col])\n",
        "\t\t\t\tdraw_text(frame, inputCentroids[col], objectID)\n",
        "\n",
        "\t\t\t\t# indicate that we have examined each of the row and\n",
        "\t\t\t\t# column indexes, respectively\n",
        "\t\t\t\tusedRows.add(row)\n",
        "\t\t\t\tusedCols.add(col)\n",
        "\n",
        "\t\t\t# compute both the row and column index we have NOT yet\n",
        "\t\t\t# examined\n",
        "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
        "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
        "\n",
        "\t\t\t# in the event that the number of object centroids is\n",
        "\t\t\t# equal or greater than the number of input centroids\n",
        "\t\t\t# we need to check and see if some of these objects have\n",
        "\t\t\t# potentially disappeared\n",
        "\t\t\tif D.shape[0] >= D.shape[1]:\n",
        "\t\t\t\t# loop over the unused row indexes\n",
        "\t\t\t\tfor row in unusedRows:\n",
        "\t\t\t\t\t# grab the object ID for the corresponding row\n",
        "\t\t\t\t\t# index and increment the disappeared counter\n",
        "\t\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t\t# check to see if the number of consecutive\n",
        "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
        "\t\t\t\t\t# for warrants deregistering the object\n",
        "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\t# otherwise, if the number of input centroids is greater\n",
        "\t\t\t# than the number of existing object centroids we need to\n",
        "\t\t\t# register each new input centroid as a trackable object\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor col in unusedCols:\n",
        "\t\t\t\t\tself.register(inputCentroids[col])\n",
        "\t\t\t\t\tdraw_centroid(frame, inputCentroids[col])\n",
        "\t\t\t\t\tdraw_text(frame, inputCentroids[col], self.nextObjectID-1)\n",
        "\n",
        "\t\t# return the set of trackable objects\n",
        "\t\treturn self.objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaFHjoofWEdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confidence_pruning(boxes, scores, min_threshold=0.3):\n",
        "  indices = np.squeeze(np.argwhere(scores >= min_threshold))\n",
        "  boxes_pruned = boxes[[indices]]\n",
        "  if boxes_pruned.ndim < 2:\n",
        "    boxes_pruned = np.expand_dims(boxes_pruned, axis=0)\n",
        "  return boxes_pruned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzl6pFtNWGwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from datetime import date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoEyW_x9VgjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today = str(date.today())\n",
        "\n",
        "### INPUT & OUTPUT VIDEO FILES ###\n",
        "#25 AGST 20 1145 1200.avi #my main vid\n",
        "#1 sept 2020 1100 1130.avi #second vid\n",
        "VIDEO_NAME = '31 agt 2020 1330 1400.avi'\n",
        "VIDEODIR = '/content/drive/My Drive/objDet/vid/' + VIDEO_NAME\n",
        "OUTDIR = '/content/drive/My Drive/objDet/outvid/' + today + '_2' + MODEL_NAME + '__' + VIDEO_NAME\n",
        "\n",
        "### SETTING UP CV2 & VIDEO ###\n",
        "cap = cv2.VideoCapture(VIDEODIR) #Getting video for cv2\n",
        "#default centerDet thresh = 0.55\n",
        "#default centerNet thresh = 0.3 ~ 0.35\n",
        "thresh = 0.45 #threshold for filtering person\n",
        "\n",
        "### VIDEO TECHNICAL ###\n",
        "ret, image_np = cap.read()\n",
        "fshape = image_np.shape\n",
        "fheight = fshape[0]\n",
        "fwidth = fshape[1]\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "print(\"fps :\",fps)\n",
        "res = (fwidth , fheight)\n",
        "print(\"res :\",res)\n",
        "#.mp4 format : *'MP4V' ; .avi : *'XVID'\n",
        "out = cv2.VideoWriter(OUTDIR,cv2.VideoWriter_fourcc(*'XVID'), fps, res)\n",
        "\n",
        "### GETTING CENTROID IF ANY DETECTION ###\n",
        "Tracker = CentroidTracker([fwidth,fheight,3], maxDisappeared=30)\n",
        "\n",
        "### LINE INTERSECT FOR COUNTING\n",
        "start_point = (0, int(fheight*0.75))\n",
        "end_point = (int(fwidth), int(fheight*0.75))\n",
        "color = (255,0,0)\n",
        "thickness = 5\n",
        "ROI_start_point = Point(start_point[0], start_point[1])\n",
        "ROI_end_point = Point(end_point[0], end_point[1])\n",
        "\n",
        "### SETTING UP WHEN to START & STOP, SHOWING DURATION ###   <---------------------------------###########################\n",
        "startDetection = 5 * 60 + 9 #when to start detect\n",
        "length = 1 * 60 #in second(s)  #Length how long to detect\n",
        "\n",
        "l_startDetection = startDetection * fps #how many frames to skip detect\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, l_startDetection) #skip frame\n",
        "l_fps = length * fps #how many frames to detect\n",
        "i = 0 #initiate first frame\n",
        "\n",
        "startTime = time.time() #how long it takes to process desired length video\n",
        "\n",
        "### IT'S ALL BEGIN ###\n",
        "if not (startDetection == 0):\n",
        "  print('{} s ARE SKIPPED!'.format(startDetection))\n",
        "print('WE ARE READY BOII!')\n",
        "\n",
        "while (i < l_fps): #start to detect\n",
        "  # Read frame from video\n",
        "  ret, image_np = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  #Draw a line for counting\n",
        "  cv2.line(image_np, start_point, end_point, color, thickness)\n",
        "\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  #image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  \n",
        "  #image_np = cv2.resize(image_np, (512, 512))\n",
        "\n",
        "  # Things to try:\n",
        "  # Flip horizontally\n",
        "  # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "  # Convert image to grayscale\n",
        "  # image_np = np.tile(\n",
        "  #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "  label_id_offset = 1\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  indices = np.squeeze(np.argwhere((detections['detection_classes'][0].numpy() + label_id_offset).astype(int) == 1))\n",
        "  boxes = detections['detection_boxes'][0].numpy()\n",
        "  boxes = boxes[[indices]]\n",
        "  classes = (detections['detection_classes'][0] + label_id_offset).numpy()\n",
        "  classes = classes[[indices]].astype(int)\n",
        "  scores = detections['detection_scores'][0].numpy()\n",
        "  scores = scores[[indices]]\n",
        "  boxes = confidence_pruning(boxes, scores, thresh)\n",
        "\n",
        "  People = Tracker.update(image_np_with_detections, boxes, ROI_start_point, ROI_end_point)\n",
        "\n",
        "  # for j in range(boxes.shape[0]):\n",
        "  #   if scores is None or scores[j] > tresh:\n",
        "  #     box = tuple(boxes[j].tolist())\n",
        "  #     x = int(((box[1]+box[0])/2) * fwidth)\n",
        "  #     y = int(((box[2]+box[3])/2) * fheight)\n",
        "  #     #print(box)\n",
        "  #   image = cv2.circle(image_np_with_detections, (x,y), 3, (0, 0, 255) , -1)\n",
        "  #     #print('scores = ',scores[i])\n",
        "\n",
        "  print(\"\\r progress: {} s / {} s\".format(str(int(((i+1)/fps))),length), end =\" \") ##\n",
        "  \n",
        "  #print(scores, str(int(((i+1)/fps)))+\" s\")\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np_with_detections,\n",
        "    #image,\n",
        "    boxes,\n",
        "    classes,\n",
        "    scores,\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    max_boxes_to_draw=200,\n",
        "    min_score_thresh=thresh,\n",
        "    agnostic_mode=False)\n",
        "\n",
        "  # Display output\n",
        "  #nFrame = cv2.resize(image_np_with_detections, (800, 600))\n",
        "  #cv2.imshow('object detection', nFrame)\n",
        "  \n",
        "  # write the frame\n",
        "  out.write(image_np_with_detections)\n",
        "\n",
        "  i = i+1\n",
        "\n",
        "  # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "  #     break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "doneTime = time.time()-startTime\n",
        "print(\"\")\n",
        "print(\"DONE! Saved as :\",OUTDIR)\n",
        "print(\"Finish in : {} (s)\".format(doneTime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buXym9GkWuRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}